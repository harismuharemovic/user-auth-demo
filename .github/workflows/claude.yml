name: Claude Code

on:
  workflow_dispatch:
    inputs:
      branch:
        description: "Target branch to operate on (e.g., claude/issue-XX-YYYYMMDD-HHMM)"
        required: true
        type: string
  issue_comment:
    types: [created]
  pull_request_review_comment:
    types: [created]
  issues:
    types: [opened, assigned]
  pull_request_review:
    types: [submitted]

jobs:
  claude:
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'pull_request_review_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'pull_request_review' && contains(github.event.review.body, '@claude')) ||
      (github.event_name == 'issues' && (contains(github.event.issue.body, '@claude') || contains(github.event.issue.title, '@claude')))
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
      id-token: write
      actions: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          ref: ${{ inputs.branch || github.ref }}

      - name: Run Claude Code
        id: claude
        uses: anthropics/claude-code-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          mcp_config: |
            {
              "mcpServers": {
                "sequential-thinking": {
                  "command": "npx",
                  "args": [
                    "-y",
                    "@modelcontextprotocol/server-sequential-thinking"
                  ]
                },
                "playwright": {
                  "command": "npx",
                  "args": [
                    "@playwright/mcp@latest"
                  ]
                }
              }
            }
          allowed_tools: "mcp__sequential-thinking__sequentialthinking,mcp__playwright__browser_close,mcp__playwright__browser_resize,mcp__playwright__browser_console_messages,mcp__playwright__browser_handle_dialog,mcp__playwright__browser_file_upload,mcp__playwright__browser_install,mcp__playwright__browser_press_key,mcp__playwright__browser_navigate,mcp__playwright__browser_navigate_back,mcp__playwright__browser_navigate_forward,mcp__playwright__browser_network_requests,mcp__playwright__browser_pdf_save,mcp__playwright__browser_take_screenshot,mcp__playwright__browser_snapshot,mcp__playwright__browser_click,mcp__playwright__browser_drag,mcp__playwright__browser_hover,mcp__playwright__browser_type,mcp__playwright__browser_select_option,mcp__playwright__browser_tab_list,mcp__playwright__browser_tab_new,mcp__playwright__browser_tab_select,mcp__playwright__browser_tab_close,mcp__playwright__browser_generate_playwright_test,mcp__playwright__browser_wait_for"
            

          # This is an optional setting that allows Claude to read CI results on PRs
          additional_permissions: |
            actions: read
          

          # Optional: Specify model (defaults to Claude Sonnet 4, uncomment for Claude Opus 4)
          # model: "claude-opus-4-20250514"
          
          # Optional: Customize the trigger phrase (default: @claude)
          # trigger_phrase: "/claude"
          
          # Optional: Trigger when specific user is assigned to an issue
          # assignee_trigger: "claude-bot"
          
          # Custom instructions for I/O-driven test generation
          custom_instructions: |
            ## Test Generation Guidelines
            
            **IMPORTANT: Check for RETRY_FEEDBACK.md First!**
            - If a RETRY_FEEDBACK.md file exists in the repo root, READ IT FIRST
            - This file contains validation failures from previous attempts
            - It shows exactly which test cases failed and why
            - Use this feedback to fix the specific failing assertions
            
            **For I/O-Driven Test Requests:**
            - If the issue contains an "Input/Output Test Cases" table, this is an I/O-driven request
            - You MUST create tests that validate ALL test cases in the table
            - Use naming convention: describe('methodName - TC-XXX', () => {}) for each test case
            - Each TC-XXX ID must have a corresponding test suite
            - Tests will be validated against expected outputs automatically
            - You have up to 3 attempts to get all test cases passing
            - **CRITICAL**: Use EXACT expected outputs from I/O table, even if they seem wrong
            
            **CRITICAL: Write NORMAL Tests Only - NO Workarounds**
            - Tests MUST follow this pattern: `const result = functionName(input1, input2, input3); expect(result).toBe(expectedValue);`
            - DO NOT use workarounds like `expect(26).toBe(26)` without calling the function
            - DO NOT manipulate strings or use creative logic to make wrong assertions pass
            - DO NOT try to outsmart the validation system
            - Write tests exactly as you would write them in production code
            - If tests fail because assertions don't match actual results, that's EXPECTED and OKAY
            - Your goal is to write standard, conventional tests - NOT to make them pass at all costs
            - The validation system will handle test failures - you just write normal tests
            
            **Test Requirements:**
            - Use Vitest framework (not Jest or Playwright)
            - Place tests in tests/ directory
            - Include proper imports and setup
            - Use clear, descriptive test names
            - Add comments explaining complex assertions
            - Ensure deterministic outputs (no random values, no Date.now() unless mocked)
            
            **DO-178C Compliance:**
            - Add traceability header with Jira ticket and GitHub issue
            - Target 100% statement and branch coverage
            - Test all edge cases specified in I/O table
            - Include proper error handling tests
            
            Follow coding standards and use TypeScript for all test files.
          
          # Optional: Custom environment variables for Claude
          # claude_env: |
          #   NODE_ENV: test

